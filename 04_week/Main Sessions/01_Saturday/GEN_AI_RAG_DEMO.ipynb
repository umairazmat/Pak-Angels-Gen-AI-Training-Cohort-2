{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhuFQYKYGNM_"
   },
   "source": [
    "Intall library in order to use the api for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxzIBRnkFfr-"
   },
   "outputs": [],
   "source": [
    "!pip install groq\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlCdrEiyGc_R"
   },
   "source": [
    "Get an api from the groq\n",
    "\n",
    "Link To get Api Key: https://console.groq.com/keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xa3v4LpMGpPl"
   },
   "outputs": [],
   "source": [
    "api_key=\"your api key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3navS0rIjfH"
   },
   "source": [
    "Choose model of your choice\n",
    "\n",
    "Link for getting Models: https://console.groq.com/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVXP_nmPIwDi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"what is ai\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLuhqTDUJu8q"
   },
   "source": [
    "Find a Dataset on which u want to make a RAG\n",
    "\n",
    "Link for the dataset: https://www.kaggle.com/datasets/utkarshx27/movies-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRKh_MD0JnAD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-XxmCbqa8xc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fx1XjNPAd6gH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQCWbPfud7pj"
   },
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDV4SyHmg5Ly"
   },
   "outputs": [],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WS4Qq613TTzJ"
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5be8z1vUoN7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV data\n",
    "csv_file = \"/content/Hydra-Movie-Scrape.csv\"  # Replace with your actual CSV file name\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Use 'Summary' or 'Short Summary' as the source for documents\n",
    "documents = df['Summary'].tolist()  # Or use df['Short Summary'].tolist()\n",
    "\n",
    "# Clean the documents list to ensure all entries are strings\n",
    "documents = [str(doc) if pd.notnull(doc) else \"\" for doc in documents]\n",
    "\n",
    "# Initialize the SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for each document\n",
    "doc_embeddings = model.encode(documents, show_progress_bar=True)\n",
    "\n",
    "# Convert to NumPy array (FAISS requires float32)\n",
    "embedding_matrix = np.array(doc_embeddings).astype(\"float32\")\n",
    "\n",
    "# Build FAISS index for efficient similarity search\n",
    "index = faiss.IndexFlatL2(embedding_matrix.shape[1])\n",
    "index.add(embedding_matrix)\n",
    "\n",
    "# Function to retrieve the most relevant document\n",
    "def retrieve(query, top_k=1):\n",
    "    query_embedding = model.encode(query)  # Encode the query\n",
    "    query_vector = np.array(query_embedding).astype(\"float32\")\n",
    "\n",
    "    # Search for the closest document in the FAISS index\n",
    "    distances, indices = index.search(np.array([query_vector]), top_k)\n",
    "    return [documents[idx] for idx in indices[0]]\n",
    "\n",
    "# Function to generate response based on retrieved document\n",
    "def generate_response(query):\n",
    "    relevant_docs = retrieve(query)\n",
    "    input_text = f\"{relevant_docs[0]} Context: {query}\"\n",
    "\n",
    "    return input_text  # Simply return the relevant document for demonstration\n",
    "\n",
    "# Test RAG with a sample query\n",
    "query = \"What are some interesting movies from the last year?\"\n",
    "response = generate_response(query)\n",
    "print(\"Generated Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRWLIAkrl8FO"
   },
   "outputs": [],
   "source": [
    "!pip install pandas faiss-cpu torch transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_yNjdS_mH8b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
